
ONLINE SURVEYS7identity and affiliations of the researchers, details of what participation will entail, and confirmation of ethical approval by a legitimate review board or ethics committee (Alessi & Martin 2010).It should be made clear to participants that the enteringofinformation to survey questions and submission oftheir response signifiesconsentfor their data to be used by the researchers.  Any inclusion or exclusion criteria should be made clear. It is possible with online survey software to set up screening questions to ensure only participants who confirm they meet certain criteria gain access to the remainder of the survey.There is an extensive literature on the wording of questions and design of questionnaires that will be covered by any good survey methodology textbook (e.g. Callegaro et al 2015, Sue & Ritter 2012). Bernard (2011) described15 well-understood rules that should be followed when constructing survey itemswhich include: be unambiguous; use vocabulary that your respondents understand; pay careful attention to contingencies and filter questions; offer respondents a ‘don’t know’ option; and avoid loaded and double-barrelledquestions.Question validation is a crucial step before a survey is issued butis often overlooked in online research.Often referred to as ‘truthfulness’ or ‘accuracy’ it seeks to confirm that the questionscapturethe anticipated data and arenot interpreted differently by researchers and participants.Validity and reliability.Validity refers to the accuracy of a survey assessed by determining the representativeness of the sample and the precision of the questions being posed in an effort to ensure that what we are aiming to measure is being measured. Four types of validity are typically included in survey research: 
ONLINE SURVEYS81.Face validity, which determines whether the questions appear reasonable for acquiring the necessary data; 2.Content validity, which ensures the questions are all focussed on the issue to be addressed and related areas; 3.Internal validity, which assesses whether the questions posed imply the desired outcome to be achieved by the survey; 4.External validity, which addresses whether the questions posed elicit answers that are generalisable (i.e. reflects the response of the entire target population). In this case results using the proposed questionnaire may be compared with results previously obtained using other methods. The principle of reliability refers to whether the questions posed elicit similar information from respondents, even if the wordings or questions structures are changed. Reliability of the survey therefore relates to the consistency of the questions and statements in a questionnaire. In breastfeeding research the issue of reliability often appears when survey respondents interpret concepts (e.g. ‘exclusivity of breastfeeding’)differently to one another, or differently to the researcher’s intention (e.g. a respondent might interpret  ‘exclusively breastfed’ to mean a baby that is currently fed only human milk, while a researcher may wish to know whether the baby has received only human milk from birth). Examples of these principles in action can be found in Emmanuel & Clow’s (2017) paper demonstrating the process of validating a survey questionnaire for assessing breastfeeding intentions and practices in Nigeria based on the modification of an Irish questionnaire, and in Aydin and Pasinlioglu’s (2018) paper demonstrating reliability and validity testing of a Turkish version of the ‘Prenatal Breastfeeding Self-Efficacy Scale’. If researchers are unable 
ONLINE SURVEYS9or unwilling to undertake appropriate pre-survey piloting and testing of their online questionnaire,they are strongly advised to consider using an existing robust research tool (Kelley et al 2003).Sample and sampling.It is not feasible in most research studies to collect data from every person in a given population, thereforeit is necessary to select a sample. The method used for selecting the sampleis integral to the external validityof the survey –it must be representative of the larger sample andbe of an optimal size to minimise sampling error. The two approaches for sampling are known as random and non-random sampling, with a number of selection techniquescontained within the two categories(Kelley et al 2003).Random samplingis employed when researchers wish to apply quantitative methods to their dataas it allows the results to be generalised to the larger population and for statistical analyses to beperformed.In simple random sampling each individual within a population is selected by chanceusing a random-numbertable or computerised random-number generator. Alternatively,systematic samples can be used where potential participants are chosen at equal intervals from the populationto be studied, e.g.every 10thpatient admittedto a given hospital, or the 2ndof every 3 mother-infant pairs in a village (e.g. Hunegnaw et al 2017).It isnot easy to use random sampling techniques with online surveys as there is no systematic way to collectatraditional probability sample of the general population using the internet (Pew Research Center 2019); there is no national list of email addresses, for instance, from which people could be sampled, and no standard convention for email addresses as thereis for phone numbers, that allows random sampling. These limitations lead researchers to use 
ONLINE SURVEYS10two other main approaches for surveying the general population online. One technique is to randomly sample and contact people via another method (telephone, mail etc) and ask them to complete the survey online. Another is to identify a defined population of interest, for instancehealth-care workers in a defined geographical area andinvite all members of this group to complete an online survey (e.g. Pol-Pons et al. (2016) used a self-administered online survey to assess breastfeeding basic competence among the total population of primary care health workers in the Girona Region of northeast Spain).The other main technique, used frequently in poor quality researchstudies, relies on convenience samples of internet users –inviting participation from whoever sees the survey online, and recruiting respondents from those who volunteer.In the latter scenario there is no way to compute sampling error or for estimating how representative a sample is of a population as a whole. With the advent of computerised survey software distributed via email and social media it is increasingly common to see published quantitative studies where data have been generated via convenienceand other non-random sampling methods which do not result in a representative sample.Sample size needed for a particular study will depend on the purpose of the survey and the type of data to be collected; large samples with rigorous collection are morepowerfuland accurate, but proportionately more time-consuming and expensive(Kelley et al 2003).If statistical analyses are to be performed using the data,then sample size calculations should be conductedto determine how many responses are needed to adequately examine the question posed.A statistician should be consulted if necessary.Data collection.
ONLINE SURVEYS11In standard survey research where a pre-determined sample has been definedin terms of size and recruitment strategy, a researcher should clearly record:1.How many times, where, and by whom were potential respondents contacted?2.How many people were approached and how many of those agreed to participate?3.How did those who agreed to participate differ from those who refused?4.What was the response rate i.e. number of usable data sets as a proportion of the number of people approached(Kelley et al 2003)?This information should be reported in study publications so that the reader can assess how successful the researchers were in obtaining data from a robust and representative sample.Because it is impossible to track how many people view a website, social media, or forwarded email announcementand choose not to participate it can be impossible to compute overall response rates for online surveys, or to assess how participants vary from non-responders(Alessi & Martin 2010).Data analysis.Many volumes have beenwritten about the analysis of survey data that cannot be summarised here, but a few keypoints will be highlighted.Firstly, thepurpose of data analysis is to summarise the data that have been collected in a way that a) provides answers to the original research questionsand b) iseasily understood.Secondly, partitioning responses into participant subgroups based on demographic characteristics gathered on the respondents is often helpful. Analysis shouldnot include any questions that were not answered by most respondents –this will bias the results. Most online survey platforms provide automatic data analysis (summary) outputs, but these may be fairly basic (e.g. proportions and averages) and will 
ONLINE SURVEYS12compute outcomes for everything, whether it is meaningful to do so or not! Some thought and common sense on the part of the researcher is needed ifusing these automated outputs, however it is preferable to download the raw data and conduct the analyses oneselfin order to become familiar with the nuances in the data and to identify any problems in responses to questions that may not have been anticipated. One principle emphasised in all survey guides is that researchers must not engage in what is sometimes calleddata dredging(Kelley et al 2003), also known as‘fishing expeditions’.When large numbers of analyses are conducted on the same data set, one in 20 of the associations found between variableswill appear statistically significant by chance, leading to reported findings being false positive outcomes(Davey Smith & Ebrahim 2002).Where researchers conduct multiple analyses and publish numerous papersfrom the same data-set it isreasonable to suspect that the data have been over-analysed.Reporting survey data.In a review of 117 published survey studies Bennet et al (2011) found that many were poorly reported, with few authorsreporting the survey questions, reporting the validity or reliability of the instrument, defining the response rate, discussing the representativeness of the sample, or identifying how missing data were handled. In an effort to improve the quality of online survey reports being submitted for publication the Journal of Medical Internet Researchpublishedthe Checklist for Reporting Results of Internet E-Surveys (CHERRIES), a statement of recommendationsanalogous to the CONSORT statement for reporting randomised trials, or the QUORUM statement for reporting systematic reviews (Eysenbach 2004).The checklist ensures that all of the issues highlighted above that might produce biased results are considered by researchers and are discussed transparently in the report, 
ONLINE SURVEYS13ranging from survey design and sample selection, throughethical approval and data protection, to pre-testing, survey administration, and data analysis.The CHERRIES checklist is therefore a useful tool for researchers to use at the outset of their study to ensure theyconsider all of the issues that might arise in the conduct of online research, and thus prevent publication.Eysenbach (2004) advises that many journals routinely reject reports of online surveysdue to their lack of rigour, however a balanced discussion with appropriate qualification of the results obtained may be publishable depending on why the survey was done, and whether the results are useful in generating hypotheses that could be confirmed in a more controlledenvironment.ConclusionsWhen conducted rigorously,online surveys can be useful tools to rapidly gain large amounts of data on specific questions from targeted samples, however many researchers are seduced by the apparent easeof conducting online surveyswithout a good understanding of the key principles of survey research. The Journal of Human Lactationeditors wish to see authors of manuscripts reporting online surveys attending to the key principles, reporting their research according to the CHERRIES checklist or similar, and being cautious in the claims made for their findings.