
NS5461revised2 7 Time out 2 Access  a  quantitati ve  research  article  that  describes  the  measures  used  for the  research  study  (this  can  be  a  cross -sectional  survey,  cohort  study  or randomised controlled  trial). Does the paper state the  validity and  reliability of the  measures  and  how  valid  they  are  to  use  with this study’s  population group? If  the measure was originally designed in the  US, is there evidence of further research  to  show  the  reliability  and  validity  of  using  the  measure  with  a  UK population?Hypothesis testing and statistical  significance A statistical hypothesis is an assumption about a population parameter (value), which  the  study  will  test.  This  assumption  may  or  may  not  be  true.  The  null hypothesis  assumes  that  changes  to  the  sample  result  purely  from  chance and  that  there  is  no  difference  between  the  two  test  scores  or  there  is  no difference  from  zero.  The  alternate  hypothesis  assumes  that  changes  are influenced by some non-random cause.  The alternate hypothesis states there is a difference if the  test is two-sided (the direction of change is  not specified and can go either  way) or the  test is one-sided, where there is a difference in a particular direction,  for example the change i n one group sample is  greater than the other group sample. For example, from Table 1, a one sample t-test compares  the  mean  scores  of  a  parameter  (value)  of  the  sample  to  a hypothesised  parameter  (estimated  value).    The  null  hypothesis  for  the  one sample t-test would be the mean birth weight of babies born on their due date is  3.4kg.  The  alternate  hypothesis  would  be  that  the  mean  birth  weight  of babies born on  their due date is  not 3.4kg (for a  two-sided  test) or  the mean birth  weight of babies born on their due date is greater than 3.4kg (for a one-sided test). Statistical  tests  usually  result  in  a  statement  of  the p  value  (probability)  to show  the  significance  of  the  results.  The  p  value  is  the probability  that  the difference  seen  between   the  scores  would  have   happened  by  chance, therefore the lower the p value is, the more likely that there is a real difference between  the  scores.  It  is  generally  accepted  that  whatever  outcome  was being tested, it is statistically  significant  if the  p value  is below  0.05.  Continui ng the one sample t-test example from above if the p value of the test applied was p  =0.03, the  null  hypothesis would be rejected and the alternate hypothesis   accepted   that   the   mean   birth   weight   is   different   from   the hypothesised  value of 3.4kg (assuming  the  two-sided  test had been applied). However,  if  the  p  value  had  been  greater  than  0.05 then  the  null  hypothesis would be accepted that the mean birth weight of babies born on their due date is not different  from 3.4kg. With p  values  very close to 0.05, small changes to the data may be enough to dri ve it either above or below the value of 0.05. If a sensitivity analyses, an analysis designed to test the robustness of the results achieved or confidence intervals, indicati ng the reliability of the estimates, are given  then it goes some  way to showi ng that  the authors  have considered the
NS5461revised2 8 effect  of  small  changes  on   the   variable  measured  or  are  stating   their confidence  in the results  found. Table 1 Common parametric  statistical  tests Statistical  test Purpose of test Example of test use One  sample t-test Compares the  mean scores of a parameter (value)  of the sample to a hypothesised  parameter (estimated value). An example  of a hypothesis  to test would  be: is the  birth weight  of babies born on their  due date equal  to 3.4kg? Paired t-test Compares two  population  means and tests that  there is no  difference between  the  two sets of observations.   This  can be done in two ways  either  assessing the change  within  an  individual  or by matching  individuals  for comparison. To compare weight before and after a diet. Two  sample t-test Compares two  sample means from the  same population. To compare pulse rate after  two types  of exercise. ANOVA (analysis  of variance) Tests  whether  or not the  means  of two or more sample groups are all equal.  ANOVA is a generalisation of the t-test  to allow  comparison where  two or more observations are made. To compare pulse rate after  two or more types  of exercise. ANCOVA (analysis  of covariance) As above,  but allowing  co-variates to be included  in the  model To comparing pulse rate after  two or more  types  of exercise, but allowing  for age or gender. Correlation coefficient Measures  the strength  of association between  two variables. Pearsons,  Spearman and Kendall correlationsare the most commonly  used. To assess the relationship  between quality  of life and cognition  scores Regression A mathematical  formula  is found  to describe the  relationship  between two variables  allowing  prediction of one from  the other.  Multiple regression allows  inclusion  of more than  one predictor and  identifies the  strongest  relationship  between variables. Assessing the relationship  between two (or more) variables,  for example, how  does blood pressure  vary  with weight? 
NS5461revised2 9 Time out 3 Access  a  quantitati ve   research  article  with  figures  and  tables   used  to represent data from a randomised controlled  trial.  Within  the analysis section locate the level of significance  that  has been set.   This may be set at p≤0.05, p≤0.01,  or  p≤0.001,  to  show  statistically  significant  findings.    Does  the analysis  use  other  statistical  tests  such  as  confidence  intervals  to  show  the significance of results?  Now  look within  the tables or  text  for the results  which show  statistically  significant  findings.  What  are  the  conclusions  drawn  from these  findings? Graphs Graphical  representations  of  the  data  are  useful  for  summarising  results. However,  it  is  important  to  look  at  any  graphs  or  plots  and  assess  whether they  make  sense.   The  axes  chosen   to   represent  data  can  easily  be misleading  if  not  interpreted  correctly.    For  example,  i n  the  two  graphs  in Figure 2, both plots show eaxctly the same data.  The first depicts  the data in the observed region of change, that is from 30 -36 while the seco nd shows the data  depicted  on  the  possible  range  of  the  entire  scale,  0-72.  The  change looks much  more dramatic on the  first scale. 
NS5461revised2 10Figure 2 Example graphs 30313233343536Timepoint12010203040506070TimepointScore on test12Tables Data  can  be  better  presented  i n  a  well  laid  out  table,  as  tables  can  provide condensed  i nformation  i n  a  precise  manner.    There  is  nothing  wrong  with presenti ng  data  based  on  small  sample  si zes,  provided  the  reader  is  made aware  of  this.    A  helpful  number  to  look  for  in  a  table  is  the  sample  si ze, usually presented as n or N.   The  number of scores reported may  not be the 
NS5461revised2 11same  as  the  total  number  of  the  sample  population,  indicating  some  data  is missing. Data summarised  within the mai n  text can be difficult to  understand and may need reading more than once to fully comprehend what is being said.   Relational descriptions  (the association between pre and post-trial measures) are  potential  areas  where  misunderstandi ng  may  occur.    If  the  score  on  a scale  goes  up  it  can  mean  that  the  object  of  measurement  is  improving  or deteriorating.  It  is  therefore  important  to  be  familiar  with  the  scales  of measurement  bei ng  used  and  their  scoring,  for  example  high  scores  on  the Quality of Life i n Dementia Scale (Logsdon et al 1999) i ndicate better quality of  life,  whereas  high  scores  on  the  Mi ni-Mental  State  Exami nation  (MMSE) (Folstein  et al 1975) indicate poorer cognitive  ability. For  reported  data,  there  are  a  number  of  considerations  to  think  about, particulary  when  the  sample size is small,  such  as:   Does  the  range  (dispersal  of  the  highest  and  lowest  scores)  of  the sample make sense? By making sense one is asking if it possible and reasonable  to  see  these  scores  in  the  population  being  studied.  Dementia   is   a   disease   associated   with   old   age   and   a   samplepopulation  aged  either  60  or  65  years  and  above  would  usually  be expected.  It is not,  however,  uncommon  for people to get dementia in their  40s  or  50s.    Therefore,  i n  a  study  of  people  with  dementia showi ng  a  lower  end  of  the  age  range  of  42  years,  consideration should  be  given  to  whether  the  study  has  included  just one  or  two participants with early onset dementia (possibly affecti ng the mean age) or  whether  the  study  specifically  looked  to  recruit  from  a  sample population  of people with early onset  dementia.   Are  the  numbers  what  one  would  expect  to  see  for  the sample  used? For a dementia study recruiting  those  with mild to moderate dementia, one  would  not  expect  to  see  very  low  cognition  scores  indicating severe dementia.   The (MMSE)   (Folstein et al 1975) has cut-offpoi ntof  24-20  for  mild  dementia,  19-10  for  moderate  dementia  and  9-0  for severe  dementia.  In  a  study  recruiting  people  with  mild  to  moderate dementia,  a  score  range  of  between  24-10  points  would therefore  be expected.   Are  the  measures  related  to  one  another  in  the  right  way?  In  a dementia study,  there may be more than one measure of cognition.   A lower score on  the MMSE i ndicates greater cogniti ve impairment while a  higher  score  on  another  scale  such  as  the  Blessed  Dementia  Scale (Blessed  et  al 1968)  i ndicates  worse  cognition,  so  one  would  not expect  to see low scores on both  of these  measures.     Was  there  any  missing  data  (look  at  n)?  If  there  is  then  one  should  look  specifically  at  the  text  to  find  out  what  has  been  done  to  handle the  missing data or has the  issue of missing values  just  been ignored. Is the mean sitti ng in  the ‘middle’ of the range, if  not, i n which direction might  the data be skewed?  If  the data are skewed then it  might  not be sensible to use standard  statistical tests.   How large is the standard deviation? To  understand the spread of the data  the  standard  deviation  shows  how  much  variation  or  dispersionthere  is  from  the  mean  (average)  score.  A  low  standard deviation 
NS5461revised2 12indicates that the scores are close to the mean, whereas high standard deviation  i ndicates  that  the  scores  are  spread  out  over  a  larger  range of values.   The  reporting  of  randomised  controlled  trials  is  guided  by  the  CONSORT statement   (Schulz  2010).     This   statement  describes  the  principles  and recommendations  for  reporting  trial  data  and  ensuring  transparency  of  the steps  taken  to  collect  a nd  collate  data  for  the  trial.  Items  of  particular  note withi n the statement are the CONSORT flowchart (CONSORT 2012) (Figure 3) and the checklist.  The checklist covers  two A4 pages and  would  not be easily reproduced  here –  it  is  easily  found  on  the  i nternet.   The  flowchart  gives  an indication  of  the  flow  of  participants  through  the  trial:  from  referral  for recruitment  to  the  study,  through  to  the  final  follow-up  assessments.  The checklist  shows  all  the  items  that  should  be  reported  throughout  a  trial  to enable  a full  appraisal of the  quality  and  robustness  of a clinical  trial.   Figure 3 Consort  flowchart (Schultz  et al 2010)Time Out 4 Access  a  quantitati ve   research  article  with  figures  and  tables   used  to represent data from a randomised controlled trial.Read the article and look at how  the  statistics  are  reported.  How  helpful  are  the  figures  and  tables  in explai ning  the  results?  Has  the  data  analysed  been  presented  according  to the  CONSORT  flowchart?   Do the  reported findings of the  study  appear justified  by the  results  reported? 
NS5461revised2 13Assessing bias There are several  types of bias that can  have an effect on the outcome of a study  (Table  2).  Making  sure  the  study  is  well  planned and  organised,  run appropriately  and  uses  appropriate  research  methods  will  control  for  the majority of these types of bias, while the remainder should be controlled for in the  way  the analysis  is conducted  and reported.   Blinding a trial, if done successfully, can elimi nate many  types of bias. People who  are  i nvolved  in  a  clinical   trial  include   the  participants,  cli nicians, researchers  and  the  analyst.  It  may  or  may  not  be  possible  to  blind  the participants and cli nicians. For example, in drug trials, placebo drugs are often offered  so  that  the  cli nicans  and  participants  are  unaware  of  which  drug  has been  prescribed  to  which  participant.  For  psycho-social  interventions  it  is often  impossible  to  deli ver  the  intervention  blinded,  as  both  the  clinician  and the   participants   are   aware   that   they   are   deliveri ng   and   receivi ng   the intervention bei ng trialled. Assessment interviews to collect outcome data may, however,  be collected by  blinded researchers.   There are often blind and unblind researchers in the cli nical trial team. Unblind researchers are responsible for dealing  with the managemant of data and are allowed  to  see  which  treatment  group  a  participant  has been  allocated  to,  to arrange attendance at interventions sessions.  The blind researcher would be responsible for collecti ng the research data and does not have any knowledge which  group  the  participant  is  allocated  too,  for  example  the  i ntervention  or control  group.  The  bli nded  researcher  would  therefore  not  be  i nfluenced  b y any  pre-conceived  ideas that  he or she holds  about  the intervention. The analyst responsible for assessing  the results of the data collected should remain bli nd for as long as possible. This is usually until at least the mai n part of  the  statisticial  analysis  has  been  completed.  This  means  that  there  is  no possible  way  any  steps  taken  i n  the  statistical  analysis  can  have  i nfluenced the  results. Bias  withi n  the  analysis  of  data  is  particularly  evident wi th  the  handling  of missing  data;  whether  the  study  i ndicates  what  type  of  analysis  the  authors did and whether this takes i nto account any missing values. Missing data may be because of research participants  (cases)  not completing all the measures or dropping out of the  trial.   There is much  literature available about issues to consider  when  faced  with  missing  data  (Le  Fanu  2002,  Wood  et  al  2004, Altman and Bland 2007). In brief, complete case analysis excludes cases with any  missing  data  and  only  uses  those  cases  that  completed  the  trial,  which can be biased if that data was not missing completely at random (the reasons for the  absence of the data is unrelated  to the  outcome of the  trial).    Intention to treat analysis i n a RCT analyses every participant from when they were  randomised  to  the  trial,  but  makes  little  inference  to  the  handli ng  of missing  data.  Per  protocol  analysis  looks  at  the  analysis  by  i ncluding  each participant  by  the  treatment  they  received  and  agai n  there  is  no  particular reference to the handli ng of missing data. For any type of study it is important to  look  at  what  considerations  are  made  for  the  data that  was  missing.  It  is 
NS5461revised2 14important to identify  the  reasons for  the missing data, for example  whether all women refused to a nswer a specific question.  If this  was the case,  then any analysis  that  does  not  take  this  into  account  wi ll  be  biased;  simply  adding gender in as a covariate may  be enough  to ensure  this  bias is accounted  for.    If  imputation  (inserting  values  for  missing  data)  was  used,  it  is  important  to ascertain whether the method of imputation was appropriate.  For example, in dementia studies the  use of carryi ng forward the  last known observation  for a participant would  not be appropriate as  this  would make the  assumption that the  participant  is  not  experiencing  the  natural  decli ne  associated  with  this disease profile, so analysis  results  could  be unduly  optimistic.  